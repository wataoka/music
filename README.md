# チュートリアル

## 概要
京都大学人工知能研究会KaiRAのプロジェクト,「MusicAI(仮)」についての大まかな計画と仕様について述べる. このプロジェクトを作曲と作詞の二つに分けそれぞれのファイル名をsongとlyricsとする. 現段階では,AIによる作曲能力は少し実用的ではないため作詞のプロジェクトを進めようかと考えている. 作詞が完成した際には,それに合わせた作曲を人間により行う. そして完成した曲をプロの歌手に歌っていただき実際に販売等を行うことを目標とする. (営利性を追求しない)

## 作曲
### 流れ
1. midi形式のファイルをパースする.
2. パースされたデータをLSTMに流す.
3. 出力

### 先行事例
・[RNN+LSTMで自動作曲して見た](https://qiita.com/komakomako/items/9ba38fc38f098c0e8b9b)
(要約)RNN+LSTMをChainerで作成し,midiファイルを時系列データとして学習させた[結果](https://s3-ap-northeast-1.amazonaws.com/komahirokazu-share/rnnlstm.mp3)こうなった.

・[ニューラルネットワークで作曲をする! Magentaを動かす](https://qiita.com/marshi/items/0f6fbbe39c4381457b0a)
(要約)MegentaというGoogleのライブラリを用いて作曲を行った. MegentaのモデルはLSTM. このモデルにmidiファイルを流して生成したところ[結果](https://soundcloud.com/ig4osq8tqokz/magenta1)こうなった。

### 雑感
- 完成したものが歌を歌うような曲ではない.
- 学習時間が長いらしい(1曲だけでも1分程度)


## 作詞
### 流れ
1. データセット(既存の歌詞)をMecabで単語に切り分ける.
2. 単語をword2vecに流し,重みを学習させる.
3. そのベクトル表現から文のベクトル表現を抽出し,それをNNで学習させる.

